{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salary prediction, episode II: make it actually work (4 points)\n",
    "\n",
    "Your main task is to use some of the tricks you've learned on the network and analyze if you can improve __validation MAE__. Try __at least 3 options__ from the list below for a passing grade. Write a short report about what you have tried. More ideas = more bonus points. \n",
    "\n",
    "__Please be serious:__ \" plot learning curves in MAE/epoch, compare models based on optimal performance, test one change at a time. You know the drill :)\n",
    "\n",
    "You can use either __pytorch__ or __tensorflow__ or any other framework (e.g. pure __keras__). Feel free to adapt the seminar code for your needs. For tensorflow version, consider `seminar_tf2.ipynb` as a starting point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244768, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./Train_rev1.csv\",index_col=None)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
    "\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(data[\"SalaryNormalized\"], bins=20);\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(data['Log1pSalary'], bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "      <th>Log1pSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>230020</th>\n",
       "      <td>72450747</td>\n",
       "      <td>Database Coordinator</td>\n",
       "      <td>Travelodge, Database Coordinator, Thame Oxford...</td>\n",
       "      <td>Thame Oxfordshire South East</td>\n",
       "      <td>Thame</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>360 Resourcing</td>\n",
       "      <td>Admin Jobs</td>\n",
       "      <td>15k per year</td>\n",
       "      <td>15000</td>\n",
       "      <td>totaljobs.com</td>\n",
       "      <td>9.615872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46855</th>\n",
       "      <td>68570450</td>\n",
       "      <td>Deputy Nursing Home Manager  RGN or RMN</td>\n",
       "      <td>Deputy Nursing Home Manager  RGN / RMN  perman...</td>\n",
       "      <td>Worcestershire - Bewdley</td>\n",
       "      <td>Bewdley</td>\n",
       "      <td>full_time</td>\n",
       "      <td>permanent</td>\n",
       "      <td>UKStaffsearch</td>\n",
       "      <td>Healthcare &amp; Nursing Jobs</td>\n",
       "      <td>28000 - 32000</td>\n",
       "      <td>30000</td>\n",
       "      <td>ukstaffsearch.com</td>\n",
       "      <td>10.308986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177355</th>\n",
       "      <td>71528398</td>\n",
       "      <td>Junior Sous Chef</td>\n",
       "      <td>Junior Sous Chef  Fine Dining Pub  **** Rosett...</td>\n",
       "      <td>North West</td>\n",
       "      <td>North West London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Platinum Recruitment Consultancy</td>\n",
       "      <td>Hospitality &amp; Catering Jobs</td>\n",
       "      <td>17000 - 20000 per annum + Live In</td>\n",
       "      <td>18500</td>\n",
       "      <td>caterer.com</td>\n",
       "      <td>9.825580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Id                                    Title  \\\n",
       "230020  72450747                     Database Coordinator   \n",
       "46855   68570450  Deputy Nursing Home Manager  RGN or RMN   \n",
       "177355  71528398                         Junior Sous Chef   \n",
       "\n",
       "                                          FullDescription  \\\n",
       "230020  Travelodge, Database Coordinator, Thame Oxford...   \n",
       "46855   Deputy Nursing Home Manager  RGN / RMN  perman...   \n",
       "177355  Junior Sous Chef  Fine Dining Pub  **** Rosett...   \n",
       "\n",
       "                         LocationRaw LocationNormalized ContractType  \\\n",
       "230020  Thame Oxfordshire South East              Thame          NaN   \n",
       "46855       Worcestershire - Bewdley            Bewdley    full_time   \n",
       "177355                    North West  North West London          NaN   \n",
       "\n",
       "       ContractTime                           Company  \\\n",
       "230020    permanent                    360 Resourcing   \n",
       "46855     permanent                     UKStaffsearch   \n",
       "177355          NaN  Platinum Recruitment Consultancy   \n",
       "\n",
       "                           Category                          SalaryRaw  \\\n",
       "230020                   Admin Jobs                       15k per year   \n",
       "46855     Healthcare & Nursing Jobs                      28000 - 32000   \n",
       "177355  Hospitality & Catering Jobs  17000 - 20000 per annum + Live In   \n",
       "\n",
       "        SalaryNormalized         SourceName  Log1pSalary  \n",
       "230020             15000      totaljobs.com     9.615872  \n",
       "46855              30000  ukstaffsearch.com    10.308986  \n",
       "177355             18500        caterer.com     9.825580  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_columns = [\"Title\", \"FullDescription\"]\n",
    "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
    "TARGET_COLUMN = \"Log1pSalary\"\n",
    "\n",
    "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast missing values to string \"NaN\"\n",
    "\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A short report\n",
    "\n",
    "Please tell us what you did and how did it work.\n",
    "\n",
    "`<YOUR_TEXT_HERE>`, i guess..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "\n",
    "def func(string: str) -> str:\n",
    "    string = str(string)\n",
    "    return ' '.join(tokenizer.tokenize(string)).lower()\n",
    "\n",
    "data['Title'] = data['Title'].apply(func)\n",
    "data['FullDescription'] = data['FullDescription'].apply(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "token_counts = Counter()\n",
    "\n",
    "for title in data['Title'].values:\n",
    "    for token in title.split():\n",
    "        token_counts[token] += 1\n",
    "\n",
    "for title in data['FullDescription'].values:\n",
    "    for token in title.split():\n",
    "        token_counts[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = 10\n",
    "\n",
    "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
    "tokens = sorted(t for t, c in token_counts.items() if c >= min_count)#TODO<YOUR CODE HERE>\n",
    "\n",
    "# Add a special tokens for unknown and empty words\n",
    "UNK, PAD = \"UNK\", \"PAD\"\n",
    "tokens = [UNK, PAD] + tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_id = dict()\n",
    "\n",
    "for first, second in enumerate(tokens):\n",
    "    token_to_id[second] = first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
    "\n",
    "def as_matrix(sequences, max_len=None):\n",
    "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
    "    if isinstance(sequences[0], str):\n",
    "        sequences = list(map(str.split, sequences))\n",
    "        \n",
    "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
    "    \n",
    "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
    "    for i,seq in enumerate(sequences):\n",
    "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
    "        matrix[i, :len(row_ix)] = row_ix\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DictVectorizer</label><div class=\"sk-toggleable__content\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DictVectorizer(dtype=<class 'numpy.float32'>, sparse=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# we only consider top-1k most frequent companies to minimize memory usage\n",
    "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
    "recognized_companies = set(top_companies)\n",
    "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
    "\n",
    "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
    "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size =  195814\n",
      "Validation size =  48954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
    "data_train.index = range(len(data_train))\n",
    "data_val.index = range(len(data_val))\n",
    "\n",
    "print(\"Train size = \", len(data_train))\n",
    "print(\"Validation size = \", len(data_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "def to_tensors(batch, device):\n",
    "    batch_tensors = dict()\n",
    "    for key, arr in batch.items():\n",
    "        if key in [\"FullDescription\", \"Title\"]:\n",
    "            batch_tensors[key] = torch.tensor(arr, device=device, dtype=torch.int64)\n",
    "        else:\n",
    "            batch_tensors[key] = torch.tensor(arr, device=device)\n",
    "    return batch_tensors\n",
    "\n",
    "\n",
    "def make_batch(data, max_len=None, word_dropout=0, device=device):\n",
    "    \"\"\"\n",
    "    Creates a keras-friendly dict from the batch data.\n",
    "    :param word_dropout: replaces token index with UNK_IX with this probability\n",
    "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
    "    \"\"\"\n",
    "    batch = {}\n",
    "    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len)\n",
    "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len)\n",
    "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
    "    \n",
    "    if word_dropout != 0:\n",
    "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
    "    \n",
    "    if TARGET_COLUMN in data.columns:\n",
    "        batch[TARGET_COLUMN] = data[TARGET_COLUMN].values\n",
    "    \n",
    "    return to_tensors(batch, device)\n",
    "\n",
    "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
    "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
    "    dropout_mask &= matrix != pad_ix\n",
    "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader\n",
    "word_embeddings = gensim.downloader.load(\"word2vec-google-news-300\")\n",
    "# Load pre-trained word embeddings (e.g., Word2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SalaryPredictor(nn.Module):\n",
    "    def __init__(self, embedding_dim=300, n_cat_features=len(categorical_vectorizer.vocabulary_)):\n",
    "        super().__init__()\n",
    "\n",
    "        # Shared Word Embeddings\n",
    "        self.emb_shared = nn.Embedding.from_pretrained(torch.FloatTensor(word_embeddings.vectors), padding_idx=0)\n",
    "\n",
    "        # Title\n",
    "        self.title_conv = nn.Conv1d(in_channels=embedding_dim, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.title_relu = nn.ReLU()\n",
    "        self.title_pooling = nn.AdaptiveMaxPool1d(1)\n",
    "        self.title_dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        # Description\n",
    "        self.descr_conv = nn.Conv1d(in_channels=embedding_dim, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.descr_relu = nn.ReLU()\n",
    "        self.descr_pooling = nn.AdaptiveMaxPool1d(1)\n",
    "        self.descr_dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        # Categorical features\n",
    "        self.cat_features_encoder = nn.Sequential(\n",
    "            nn.Linear(n_cat_features, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(p=0.5)\n",
    "        )\n",
    "\n",
    "        # Common network\n",
    "        self.common_network = nn.Sequential(\n",
    "            nn.Linear(2 + 128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, batch):\n",
    "        title_data = batch['Title']\n",
    "        description_data = batch['FullDescription']\n",
    "        cat_features_data = batch['Categorical']\n",
    "\n",
    "        # Shared Word Embeddings\n",
    "        emb_shared_title = self.emb_shared(title_data)\n",
    "        emb_shared_descr = self.emb_shared(description_data)\n",
    "\n",
    "        # Title\n",
    "        title_conv = self.title_conv(emb_shared_title.transpose(2, 1))\n",
    "        title_relu = self.title_relu(title_conv)\n",
    "        title_pooled = torch.max(title_relu, dim=-1).values\n",
    "        title_pooled = self.title_dropout(title_pooled)\n",
    "        title_pooled = self.title_pooling(title_pooled)\n",
    "\n",
    "        # Description\n",
    "        descr_conv = self.descr_conv(emb_shared_descr.transpose(2, 1))\n",
    "        descr_relu = self.descr_relu(descr_conv)\n",
    "        descr_pooled = torch.max(descr_relu, dim=-1).values\n",
    "        descr_pooled = self.descr_dropout(descr_pooled)\n",
    "        descr_pooled = self.descr_pooling(descr_pooled)\n",
    "\n",
    "        # Categorical features\n",
    "        cat_features_encoded = self.cat_features_encoder(cat_features_data)\n",
    "\n",
    "        # Concatenate and pass through the common network\n",
    "        combined_features = torch.cat([title_pooled, descr_pooled, cat_features_encoded], dim=1)\n",
    "        predicted_salary = self.common_network(combined_features)\n",
    "\n",
    "        return predicted_salary.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SalaryPredictor()\n",
    "model = SalaryPredictor().to(device)\n",
    "batch = make_batch(data_train[:100], device=device)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1474, -0.4269,  0.3165, -0.4344, -0.1292,  0.1329, -0.0988,  0.3474,\n",
      "         0.1000, -0.3508,  0.1084,  0.5270,  0.1537,  0.3537, -0.4094,  0.2254,\n",
      "         0.4776, -0.3122,  0.4421, -0.0690, -0.8605, -0.1492,  0.3964, -0.1865,\n",
      "        -0.2612, -0.6227, -0.6536,  0.2747, -0.4292,  0.2620, -0.2218,  0.0882,\n",
      "        -0.1417, -0.1848, -0.4746, -0.0026, -0.4085, -0.4418, -0.2446, -0.2377,\n",
      "        -0.4531, -0.5507,  0.9627,  0.4769, -0.1280,  0.6502, -0.1306, -0.1224,\n",
      "        -0.0167,  0.3710,  0.2930, -0.0558, -0.0517,  0.3979, -0.3079, -0.2211,\n",
      "         0.2037,  0.0222,  0.0937, -0.2284, -0.0462,  0.3929, -0.2048, -0.5232,\n",
      "         0.2093,  0.1201,  0.0302, -0.1363, -0.1575,  0.0841, -0.8561,  0.7229,\n",
      "         0.5787, -0.4132,  0.6076, -0.1725,  0.1938,  0.0597, -0.5880, -0.0139,\n",
      "         0.4023, -0.4129,  0.0949,  0.2000, -0.7902,  0.1194,  0.1541, -0.5470,\n",
      "         0.1960,  0.1433,  0.8777,  0.1447,  0.0539, -0.3496, -0.9201, -0.6731,\n",
      "         0.0874, -0.2530,  0.0544, -0.4224], grad_fn=<SqueezeBackward0>)\n",
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "dummy_pred = model(batch)\n",
    "dummy_loss = criterion(dummy_pred, batch[TARGET_COLUMN])\n",
    "print(dummy_pred)\n",
    "print(dummy_pred.shape)\n",
    "assert dummy_pred.shape == torch.Size([100])\n",
    "assert len(torch.unique(dummy_pred)) > 20, \"model returns suspiciously few unique outputs. Check your initialization\"\n",
    "assert dummy_loss.ndim == 0 and 0. <= dummy_loss <= 250., \"make sure you minimize MSE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_minibatches(data, batch_size=256, shuffle=True, cycle=False, device=device, **kwargs):\n",
    "    \"\"\" iterates minibatches of data in random order \"\"\"\n",
    "    while True:\n",
    "        indices = np.arange(len(data))\n",
    "        if shuffle:\n",
    "            indices = np.random.permutation(indices)\n",
    "\n",
    "        for start in range(0, len(indices), batch_size):\n",
    "            batch = make_batch(data.iloc[indices[start : start + batch_size]], device=device, **kwargs)\n",
    "            yield batch\n",
    "        \n",
    "        if not cycle: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(model, data, batch_size=BATCH_SIZE, name=\"\", device=torch.device('cpu'), **kw):\n",
    "    squared_error = abs_error = num_samples = 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterate_minibatches(data, batch_size=batch_size, shuffle=False, device=device, **kw):\n",
    "            batch_pred = model(batch)\n",
    "            squared_error += torch.sum(torch.square(batch_pred - batch[TARGET_COLUMN]))\n",
    "            abs_error += torch.sum(torch.abs(batch_pred - batch[TARGET_COLUMN]))\n",
    "            num_samples += len(batch_pred)\n",
    "    mse = squared_error.detach().cpu().numpy() / num_samples\n",
    "    mae = abs_error.detach().cpu().numpy() / num_samples\n",
    "    print(\"%s results:\" % (name or \"\"))\n",
    "    print(\"Mean square error: %.5f\" % mse)\n",
    "    print(\"Mean absolute error: %.5f\" % mae)\n",
    "    return mse, mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------epoch: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf2fbcb170fd410a8a650061dfe73aa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.49953\n",
      "Mean absolute error: 0.59896\n",
      "------------epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74603a8a2556445ea759295cc36a5fe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.30924\n",
      "Mean absolute error: 0.45343\n",
      "------------epoch: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac95037f53d0484c9764e8583805c56c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.24207\n",
      "Mean absolute error: 0.39203\n",
      "------------epoch: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93668dc1f1a34b599dee704a3be94bdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.20249\n",
      "Mean absolute error: 0.35632\n",
      "------------epoch: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a7cd20edca94f54b8bc4ae8dd5d1871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.17473\n",
      "Mean absolute error: 0.32824\n",
      "------------epoch: 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8589e034640c4d13bd53e5689709c0f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.14989\n",
      "Mean absolute error: 0.30083\n",
      "------------epoch: 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d984cf19ac96402580c3797011ff94b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.15141\n",
      "Mean absolute error: 0.30318\n",
      "------------epoch: 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e434d4b8a9a402cb2611beb8c464ba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.14534\n",
      "Mean absolute error: 0.29590\n",
      "------------epoch: 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4439608d59124413896afb97bed099f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.13996\n",
      "Mean absolute error: 0.28970\n",
      "------------epoch: 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "225a798f0ff942909d9566c489af43d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.14329\n",
      "Mean absolute error: 0.29334\n"
     ]
    }
   ],
   "source": [
    "model = SalaryPredictor().to(device)\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"------------epoch: {epoch}\")\n",
    "    model.train()\n",
    "    for i, batch in tqdm(enumerate(\n",
    "            iterate_minibatches(data_train, batch_size=BATCH_SIZE, device=device)),\n",
    "            total=len(data_train) // BATCH_SIZE\n",
    "        ):\n",
    "        pred = model(batch)\n",
    "        loss = criterion(pred, batch[TARGET_COLUMN])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print_metrics(model, data_val, device=device)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommended options\n",
    "\n",
    "#### A) CNN architecture\n",
    "\n",
    "All the tricks you know about dense and convolutional neural networks apply here as well.\n",
    "* Dropout. Nuff said.\n",
    "* Batch Norm. This time it's `nn.BatchNorm*`/`L.BatchNormalization`\n",
    "* Parallel convolution layers. The idea is that you apply several nn.Conv1d to the same embeddings and concatenate output channels.\n",
    "* More layers, more neurons, ya know...\n",
    "\n",
    "\n",
    "#### B) Play with pooling\n",
    "\n",
    "There's more than one way to perform pooling:\n",
    "* Max over time (independently for each feature)\n",
    "* Average over time (excluding PAD)\n",
    "* Softmax-pooling:\n",
    "$$ out_{i, t} = \\sum_t {h_{i,t} \\cdot {{e ^ {h_{i, t}}} \\over \\sum_\\tau e ^ {h_{j, \\tau}} } }$$\n",
    "\n",
    "* Attentive pooling\n",
    "$$ out_{i, t} = \\sum_t {h_{i,t} \\cdot Attn(h_t)}$$\n",
    "\n",
    ", where $$ Attn(h_t) = {{e ^ {NN_{attn}(h_t)}} \\over \\sum_\\tau e ^ {NN_{attn}(h_\\tau)}}  $$\n",
    "and $NN_{attn}$ is a dense layer.\n",
    "\n",
    "The optimal score is usually achieved by concatenating several different poolings, including several attentive pooling with different $NN_{attn}$ (aka multi-headed attention).\n",
    "\n",
    "The catch is that keras layers do not inlude those toys. You will have to [write your own keras layer](https://keras.io/layers/writing-your-own-keras-layers/). Or use pure tensorflow, it might even be easier :)\n",
    "\n",
    "#### C) Fun with words\n",
    "\n",
    "It's not always a good idea to train embeddings from scratch. Here's a few tricks:\n",
    "\n",
    "* Use a pre-trained embeddings from `gensim.downloader.load`. See last lecture.\n",
    "* Start with pre-trained embeddings, then fine-tune them with gradient descent. You may or may not download pre-trained embeddings from [here](http://nlp.stanford.edu/data/glove.6B.zip) and follow this [manual](https://keras.io/examples/nlp/pretrained_word_embeddings/) to initialize your Keras embedding layer with downloaded weights.\n",
    "* Use the same embedding matrix in title and desc vectorizer\n",
    "\n",
    "\n",
    "#### D) Going recurrent\n",
    "\n",
    "We've already learned that recurrent networks can do cool stuff in sequence modelling. Turns out, they're not useless for classification as well. With some tricks of course..\n",
    "\n",
    "* Like convolutional layers, LSTM should be pooled into a fixed-size vector with some of the poolings.\n",
    "* Since you know all the text in advance, use bidirectional RNN\n",
    "  * Run one LSTM from left to right\n",
    "  * Run another in parallel from right to left \n",
    "  * Concatenate their output sequences along unit axis (dim=-1)\n",
    "\n",
    "* It might be good idea to mix convolutions and recurrent layers differently for title and description\n",
    "\n",
    "\n",
    "#### E) Optimizing seriously\n",
    "\n",
    "* You don't necessarily need 100 epochs. Use early stopping. If you've never done this before, take a look at [early stopping callback(keras)](https://keras.io/callbacks/#earlystopping) or in [pytorch(lightning)](https://pytorch-lightning.readthedocs.io/en/latest/common/early_stopping.html).\n",
    "  * In short, train until you notice that validation\n",
    "  * Maintain the best-on-validation snapshot via `model.save(file_name)`\n",
    "  * Plotting learning curves is usually a good idea\n",
    "  \n",
    "Good luck! And may the force be with you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
